{
  "best_metric": 0.8379076719284058,
  "best_model_checkpoint": "Modelos/HelBERT-base-uncased-scratch/checkpoint-113988",
  "epoch": 2.99998684089324,
  "global_step": 113988,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "learning_rate": 5e-06,
      "loss": 0.8811,
      "step": 500
    },
    {
      "epoch": 0.03,
      "learning_rate": 1e-05,
      "loss": 0.8727,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "learning_rate": 1.5e-05,
      "loss": 0.8643,
      "step": 1500
    },
    {
      "epoch": 0.05,
      "learning_rate": 2e-05,
      "loss": 0.8615,
      "step": 2000
    },
    {
      "epoch": 0.07,
      "learning_rate": 2.5e-05,
      "loss": 0.854,
      "step": 2500
    },
    {
      "epoch": 0.08,
      "learning_rate": 3e-05,
      "loss": 0.8503,
      "step": 3000
    },
    {
      "epoch": 0.09,
      "learning_rate": 3.499e-05,
      "loss": 0.8454,
      "step": 3500
    },
    {
      "epoch": 0.11,
      "learning_rate": 3.999e-05,
      "loss": 0.8459,
      "step": 4000
    },
    {
      "epoch": 0.12,
      "learning_rate": 4.499e-05,
      "loss": 0.8457,
      "step": 4500
    },
    {
      "epoch": 0.13,
      "learning_rate": 4.9980000000000006e-05,
      "loss": 0.847,
      "step": 5000
    },
    {
      "epoch": 0.14,
      "learning_rate": 5.498e-05,
      "loss": 0.8432,
      "step": 5500
    },
    {
      "epoch": 0.16,
      "learning_rate": 5.9980000000000005e-05,
      "loss": 0.8465,
      "step": 6000
    },
    {
      "epoch": 0.17,
      "learning_rate": 6.498e-05,
      "loss": 0.8509,
      "step": 6500
    },
    {
      "epoch": 0.18,
      "learning_rate": 6.998e-05,
      "loss": 0.8481,
      "step": 7000
    },
    {
      "epoch": 0.2,
      "learning_rate": 7.498e-05,
      "loss": 0.8613,
      "step": 7500
    },
    {
      "epoch": 0.21,
      "learning_rate": 7.998e-05,
      "loss": 0.8492,
      "step": 8000
    },
    {
      "epoch": 0.22,
      "learning_rate": 8.498e-05,
      "loss": 0.8652,
      "step": 8500
    },
    {
      "epoch": 0.24,
      "learning_rate": 8.998e-05,
      "loss": 0.8701,
      "step": 9000
    },
    {
      "epoch": 0.25,
      "learning_rate": 9.497000000000001e-05,
      "loss": 0.8765,
      "step": 9500
    },
    {
      "epoch": 0.26,
      "learning_rate": 9.997e-05,
      "loss": 0.8758,
      "step": 10000
    },
    {
      "epoch": 0.28,
      "learning_rate": 9.986566115255704e-05,
      "loss": 0.8818,
      "step": 10500
    },
    {
      "epoch": 0.29,
      "learning_rate": 9.973051140663856e-05,
      "loss": 0.8828,
      "step": 11000
    },
    {
      "epoch": 0.3,
      "learning_rate": 9.959536166072009e-05,
      "loss": 0.8853,
      "step": 11500
    },
    {
      "epoch": 0.32,
      "learning_rate": 9.946021191480161e-05,
      "loss": 0.8896,
      "step": 12000
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.932506216888313e-05,
      "loss": 0.8892,
      "step": 12500
    },
    {
      "epoch": 0.34,
      "learning_rate": 9.918991242296465e-05,
      "loss": 0.8891,
      "step": 13000
    },
    {
      "epoch": 0.36,
      "learning_rate": 9.905503297653801e-05,
      "loss": 0.8929,
      "step": 13500
    },
    {
      "epoch": 0.37,
      "learning_rate": 9.892015353011138e-05,
      "loss": 0.8969,
      "step": 14000
    },
    {
      "epoch": 0.38,
      "learning_rate": 9.878500378419289e-05,
      "loss": 0.8951,
      "step": 14500
    },
    {
      "epoch": 0.39,
      "learning_rate": 9.864985403827441e-05,
      "loss": 0.9026,
      "step": 15000
    },
    {
      "epoch": 0.41,
      "learning_rate": 9.851497459184778e-05,
      "loss": 0.8994,
      "step": 15500
    },
    {
      "epoch": 0.42,
      "learning_rate": 9.837982484592929e-05,
      "loss": 0.8917,
      "step": 16000
    },
    {
      "epoch": 0.43,
      "learning_rate": 9.824521569899449e-05,
      "loss": 0.8979,
      "step": 16500
    },
    {
      "epoch": 0.45,
      "learning_rate": 9.811006595307602e-05,
      "loss": 0.9013,
      "step": 17000
    },
    {
      "epoch": 0.46,
      "learning_rate": 9.797491620715753e-05,
      "loss": 0.8962,
      "step": 17500
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.783976646123906e-05,
      "loss": 0.8979,
      "step": 18000
    },
    {
      "epoch": 0.49,
      "learning_rate": 9.770461671532059e-05,
      "loss": 0.8919,
      "step": 18500
    },
    {
      "epoch": 0.5,
      "learning_rate": 9.75694669694021e-05,
      "loss": 0.8989,
      "step": 19000
    },
    {
      "epoch": 0.51,
      "learning_rate": 9.743431722348362e-05,
      "loss": 0.8904,
      "step": 19500
    },
    {
      "epoch": 0.53,
      "learning_rate": 9.729916747756515e-05,
      "loss": 0.8955,
      "step": 20000
    },
    {
      "epoch": 0.54,
      "learning_rate": 9.716401773164667e-05,
      "loss": 0.8975,
      "step": 20500
    },
    {
      "epoch": 0.55,
      "learning_rate": 9.70288679857282e-05,
      "loss": 0.902,
      "step": 21000
    },
    {
      "epoch": 0.57,
      "learning_rate": 9.689371823980972e-05,
      "loss": 0.903,
      "step": 21500
    },
    {
      "epoch": 0.58,
      "learning_rate": 9.675856849389123e-05,
      "loss": 0.8971,
      "step": 22000
    },
    {
      "epoch": 0.59,
      "learning_rate": 9.662341874797277e-05,
      "loss": 0.9022,
      "step": 22500
    },
    {
      "epoch": 0.61,
      "learning_rate": 9.648853930154612e-05,
      "loss": 0.9045,
      "step": 23000
    },
    {
      "epoch": 0.62,
      "learning_rate": 9.635338955562764e-05,
      "loss": 0.8947,
      "step": 23500
    },
    {
      "epoch": 0.63,
      "learning_rate": 9.621823980970917e-05,
      "loss": 0.9016,
      "step": 24000
    },
    {
      "epoch": 0.64,
      "learning_rate": 9.608309006379068e-05,
      "loss": 0.8991,
      "step": 24500
    },
    {
      "epoch": 0.66,
      "learning_rate": 9.594794031787221e-05,
      "loss": 0.8964,
      "step": 25000
    },
    {
      "epoch": 0.67,
      "learning_rate": 9.58133311709374e-05,
      "loss": 0.8933,
      "step": 25500
    },
    {
      "epoch": 0.68,
      "learning_rate": 9.567818142501892e-05,
      "loss": 0.8979,
      "step": 26000
    },
    {
      "epoch": 0.7,
      "learning_rate": 9.554303167910045e-05,
      "loss": 0.8987,
      "step": 26500
    },
    {
      "epoch": 0.71,
      "learning_rate": 9.540788193318198e-05,
      "loss": 0.8966,
      "step": 27000
    },
    {
      "epoch": 0.72,
      "learning_rate": 9.527273218726349e-05,
      "loss": 0.8991,
      "step": 27500
    },
    {
      "epoch": 0.74,
      "learning_rate": 9.513758244134501e-05,
      "loss": 0.8966,
      "step": 28000
    },
    {
      "epoch": 0.75,
      "learning_rate": 9.500243269542654e-05,
      "loss": 0.9026,
      "step": 28500
    },
    {
      "epoch": 0.76,
      "learning_rate": 9.486728294950806e-05,
      "loss": 0.902,
      "step": 29000
    },
    {
      "epoch": 0.78,
      "learning_rate": 9.473213320358958e-05,
      "loss": 0.9019,
      "step": 29500
    },
    {
      "epoch": 0.79,
      "learning_rate": 9.459698345767111e-05,
      "loss": 0.9025,
      "step": 30000
    },
    {
      "epoch": 0.8,
      "learning_rate": 9.446183371175262e-05,
      "loss": 0.8966,
      "step": 30500
    },
    {
      "epoch": 0.82,
      "learning_rate": 9.432668396583416e-05,
      "loss": 0.8989,
      "step": 31000
    },
    {
      "epoch": 0.83,
      "learning_rate": 9.419153421991567e-05,
      "loss": 0.8994,
      "step": 31500
    },
    {
      "epoch": 0.84,
      "learning_rate": 9.405638447399719e-05,
      "loss": 0.9037,
      "step": 32000
    },
    {
      "epoch": 0.86,
      "learning_rate": 9.392150502757056e-05,
      "loss": 0.9007,
      "step": 32500
    },
    {
      "epoch": 0.87,
      "learning_rate": 9.378635528165207e-05,
      "loss": 0.9063,
      "step": 33000
    },
    {
      "epoch": 0.88,
      "learning_rate": 9.36512055357336e-05,
      "loss": 0.9008,
      "step": 33500
    },
    {
      "epoch": 0.89,
      "learning_rate": 9.351605578981511e-05,
      "loss": 0.8968,
      "step": 34000
    },
    {
      "epoch": 0.91,
      "learning_rate": 9.338090604389664e-05,
      "loss": 0.9001,
      "step": 34500
    },
    {
      "epoch": 0.92,
      "learning_rate": 9.324575629797816e-05,
      "loss": 0.8996,
      "step": 35000
    },
    {
      "epoch": 0.93,
      "learning_rate": 9.311060655205969e-05,
      "loss": 0.8903,
      "step": 35500
    },
    {
      "epoch": 0.95,
      "learning_rate": 9.297545680614121e-05,
      "loss": 0.894,
      "step": 36000
    },
    {
      "epoch": 0.96,
      "learning_rate": 9.284030706022273e-05,
      "loss": 0.898,
      "step": 36500
    },
    {
      "epoch": 0.97,
      "learning_rate": 9.270515731430426e-05,
      "loss": 0.8952,
      "step": 37000
    },
    {
      "epoch": 0.99,
      "learning_rate": 9.257000756838578e-05,
      "loss": 0.8987,
      "step": 37500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8734428286552429,
      "eval_runtime": 167.5659,
      "eval_samples_per_second": 596.78,
      "eval_steps_per_second": 18.649,
      "step": 37996
    },
    {
      "epoch": 1.0,
      "learning_rate": 9.24348578224673e-05,
      "loss": 0.8937,
      "step": 38000
    },
    {
      "epoch": 1.01,
      "learning_rate": 9.229997837604066e-05,
      "loss": 0.8888,
      "step": 38500
    },
    {
      "epoch": 1.03,
      "learning_rate": 9.216482863012218e-05,
      "loss": 0.8939,
      "step": 39000
    },
    {
      "epoch": 1.04,
      "learning_rate": 9.20296788842037e-05,
      "loss": 0.8895,
      "step": 39500
    },
    {
      "epoch": 1.05,
      "learning_rate": 9.189452913828523e-05,
      "loss": 0.8924,
      "step": 40000
    },
    {
      "epoch": 1.07,
      "learning_rate": 9.175964969185858e-05,
      "loss": 0.8921,
      "step": 40500
    },
    {
      "epoch": 1.08,
      "learning_rate": 9.162477024543195e-05,
      "loss": 0.8909,
      "step": 41000
    },
    {
      "epoch": 1.09,
      "learning_rate": 9.148962049951346e-05,
      "loss": 0.895,
      "step": 41500
    },
    {
      "epoch": 1.11,
      "learning_rate": 9.1354470753595e-05,
      "loss": 0.8863,
      "step": 42000
    },
    {
      "epoch": 1.12,
      "learning_rate": 9.12193210076765e-05,
      "loss": 0.8855,
      "step": 42500
    },
    {
      "epoch": 1.13,
      "learning_rate": 9.108444156124987e-05,
      "loss": 0.8873,
      "step": 43000
    },
    {
      "epoch": 1.14,
      "learning_rate": 9.094929181533139e-05,
      "loss": 0.8907,
      "step": 43500
    },
    {
      "epoch": 1.16,
      "learning_rate": 9.081414206941292e-05,
      "loss": 0.8862,
      "step": 44000
    },
    {
      "epoch": 1.17,
      "learning_rate": 9.067899232349444e-05,
      "loss": 0.8915,
      "step": 44500
    },
    {
      "epoch": 1.18,
      "learning_rate": 9.054384257757595e-05,
      "loss": 0.8845,
      "step": 45000
    },
    {
      "epoch": 1.2,
      "learning_rate": 9.040869283165749e-05,
      "loss": 0.8909,
      "step": 45500
    },
    {
      "epoch": 1.21,
      "learning_rate": 9.0273543085739e-05,
      "loss": 0.8913,
      "step": 46000
    },
    {
      "epoch": 1.22,
      "learning_rate": 9.013839333982052e-05,
      "loss": 0.8908,
      "step": 46500
    },
    {
      "epoch": 1.24,
      "learning_rate": 9.000351389339389e-05,
      "loss": 0.8867,
      "step": 47000
    },
    {
      "epoch": 1.25,
      "learning_rate": 8.98683641474754e-05,
      "loss": 0.8939,
      "step": 47500
    },
    {
      "epoch": 1.26,
      "learning_rate": 8.973321440155694e-05,
      "loss": 0.8891,
      "step": 48000
    },
    {
      "epoch": 1.28,
      "learning_rate": 8.959806465563845e-05,
      "loss": 0.8883,
      "step": 48500
    },
    {
      "epoch": 1.29,
      "learning_rate": 8.946291490971997e-05,
      "loss": 0.8898,
      "step": 49000
    },
    {
      "epoch": 1.3,
      "learning_rate": 8.93277651638015e-05,
      "loss": 0.8877,
      "step": 49500
    },
    {
      "epoch": 1.32,
      "learning_rate": 8.919261541788302e-05,
      "loss": 0.8909,
      "step": 50000
    },
    {
      "epoch": 1.33,
      "learning_rate": 8.905800627094821e-05,
      "loss": 0.8861,
      "step": 50500
    },
    {
      "epoch": 1.34,
      "learning_rate": 8.892285652502974e-05,
      "loss": 0.8893,
      "step": 51000
    },
    {
      "epoch": 1.36,
      "learning_rate": 8.878770677911126e-05,
      "loss": 0.8922,
      "step": 51500
    },
    {
      "epoch": 1.37,
      "learning_rate": 8.865255703319278e-05,
      "loss": 0.89,
      "step": 52000
    },
    {
      "epoch": 1.38,
      "learning_rate": 8.851740728727431e-05,
      "loss": 0.8841,
      "step": 52500
    },
    {
      "epoch": 1.39,
      "learning_rate": 8.838225754135583e-05,
      "loss": 0.8894,
      "step": 53000
    },
    {
      "epoch": 1.41,
      "learning_rate": 8.824710779543734e-05,
      "loss": 0.8926,
      "step": 53500
    },
    {
      "epoch": 1.42,
      "learning_rate": 8.811195804951888e-05,
      "loss": 0.8934,
      "step": 54000
    },
    {
      "epoch": 1.43,
      "learning_rate": 8.797680830360039e-05,
      "loss": 0.8888,
      "step": 54500
    },
    {
      "epoch": 1.45,
      "learning_rate": 8.784165855768191e-05,
      "loss": 0.8886,
      "step": 55000
    },
    {
      "epoch": 1.46,
      "learning_rate": 8.770650881176344e-05,
      "loss": 0.8905,
      "step": 55500
    },
    {
      "epoch": 1.47,
      "learning_rate": 8.757162936533679e-05,
      "loss": 0.8917,
      "step": 56000
    },
    {
      "epoch": 1.49,
      "learning_rate": 8.743647961941833e-05,
      "loss": 0.8908,
      "step": 56500
    },
    {
      "epoch": 1.5,
      "learning_rate": 8.730132987349984e-05,
      "loss": 0.8862,
      "step": 57000
    },
    {
      "epoch": 1.51,
      "learning_rate": 8.716618012758136e-05,
      "loss": 0.8893,
      "step": 57500
    },
    {
      "epoch": 1.53,
      "learning_rate": 8.703103038166288e-05,
      "loss": 0.8866,
      "step": 58000
    },
    {
      "epoch": 1.54,
      "learning_rate": 8.689588063574441e-05,
      "loss": 0.8849,
      "step": 58500
    },
    {
      "epoch": 1.55,
      "learning_rate": 8.676100118931777e-05,
      "loss": 0.888,
      "step": 59000
    },
    {
      "epoch": 1.57,
      "learning_rate": 8.662585144339928e-05,
      "loss": 0.8899,
      "step": 59500
    },
    {
      "epoch": 1.58,
      "learning_rate": 8.649070169748081e-05,
      "loss": 0.8899,
      "step": 60000
    },
    {
      "epoch": 1.59,
      "learning_rate": 8.635555195156233e-05,
      "loss": 0.8884,
      "step": 60500
    },
    {
      "epoch": 1.61,
      "learning_rate": 8.622040220564386e-05,
      "loss": 0.8907,
      "step": 61000
    },
    {
      "epoch": 1.62,
      "learning_rate": 8.608552275921722e-05,
      "loss": 0.882,
      "step": 61500
    },
    {
      "epoch": 1.63,
      "learning_rate": 8.595037301329873e-05,
      "loss": 0.884,
      "step": 62000
    },
    {
      "epoch": 1.64,
      "learning_rate": 8.581522326738027e-05,
      "loss": 0.887,
      "step": 62500
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.568007352146178e-05,
      "loss": 0.888,
      "step": 63000
    },
    {
      "epoch": 1.67,
      "learning_rate": 8.55449237755433e-05,
      "loss": 0.8882,
      "step": 63500
    },
    {
      "epoch": 1.68,
      "learning_rate": 8.540977402962483e-05,
      "loss": 0.8867,
      "step": 64000
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.527462428370635e-05,
      "loss": 0.8869,
      "step": 64500
    },
    {
      "epoch": 1.71,
      "learning_rate": 8.513947453778788e-05,
      "loss": 0.8829,
      "step": 65000
    },
    {
      "epoch": 1.72,
      "learning_rate": 8.50043247918694e-05,
      "loss": 0.8819,
      "step": 65500
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.486917504595092e-05,
      "loss": 0.882,
      "step": 66000
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.473429559952427e-05,
      "loss": 0.884,
      "step": 66500
    },
    {
      "epoch": 1.76,
      "learning_rate": 8.45991458536058e-05,
      "loss": 0.8798,
      "step": 67000
    },
    {
      "epoch": 1.78,
      "learning_rate": 8.446399610768732e-05,
      "loss": 0.8842,
      "step": 67500
    },
    {
      "epoch": 1.79,
      "learning_rate": 8.432884636176885e-05,
      "loss": 0.8905,
      "step": 68000
    },
    {
      "epoch": 1.8,
      "learning_rate": 8.419423721483404e-05,
      "loss": 0.8853,
      "step": 68500
    },
    {
      "epoch": 1.82,
      "learning_rate": 8.40593577684074e-05,
      "loss": 0.8797,
      "step": 69000
    },
    {
      "epoch": 1.83,
      "learning_rate": 8.392420802248893e-05,
      "loss": 0.8793,
      "step": 69500
    },
    {
      "epoch": 1.84,
      "learning_rate": 8.378905827657044e-05,
      "loss": 0.8817,
      "step": 70000
    },
    {
      "epoch": 1.86,
      "learning_rate": 8.365390853065198e-05,
      "loss": 0.8861,
      "step": 70500
    },
    {
      "epoch": 1.87,
      "learning_rate": 8.351875878473349e-05,
      "loss": 0.8823,
      "step": 71000
    },
    {
      "epoch": 1.88,
      "learning_rate": 8.338360903881501e-05,
      "loss": 0.8808,
      "step": 71500
    },
    {
      "epoch": 1.89,
      "learning_rate": 8.324845929289653e-05,
      "loss": 0.8797,
      "step": 72000
    },
    {
      "epoch": 1.91,
      "learning_rate": 8.311330954697806e-05,
      "loss": 0.8836,
      "step": 72500
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.297815980105957e-05,
      "loss": 0.8785,
      "step": 73000
    },
    {
      "epoch": 1.93,
      "learning_rate": 8.28430100551411e-05,
      "loss": 0.8759,
      "step": 73500
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.270786030922262e-05,
      "loss": 0.8802,
      "step": 74000
    },
    {
      "epoch": 1.96,
      "learning_rate": 8.257271056330414e-05,
      "loss": 0.8813,
      "step": 74500
    },
    {
      "epoch": 1.97,
      "learning_rate": 8.243810141636933e-05,
      "loss": 0.8765,
      "step": 75000
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.230295167045087e-05,
      "loss": 0.881,
      "step": 75500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8565044403076172,
      "eval_runtime": 167.9707,
      "eval_samples_per_second": 595.342,
      "eval_steps_per_second": 18.604,
      "step": 75992
    },
    {
      "epoch": 2.0,
      "learning_rate": 8.216807222402422e-05,
      "loss": 0.8786,
      "step": 76000
    },
    {
      "epoch": 2.01,
      "learning_rate": 8.203346307708943e-05,
      "loss": 0.8775,
      "step": 76500
    },
    {
      "epoch": 2.03,
      "learning_rate": 8.189831333117094e-05,
      "loss": 0.8703,
      "step": 77000
    },
    {
      "epoch": 2.04,
      "learning_rate": 8.176316358525246e-05,
      "loss": 0.8652,
      "step": 77500
    },
    {
      "epoch": 2.05,
      "learning_rate": 8.162801383933399e-05,
      "loss": 0.8763,
      "step": 78000
    },
    {
      "epoch": 2.07,
      "learning_rate": 8.149286409341551e-05,
      "loss": 0.866,
      "step": 78500
    },
    {
      "epoch": 2.08,
      "learning_rate": 8.135771434749702e-05,
      "loss": 0.8721,
      "step": 79000
    },
    {
      "epoch": 2.09,
      "learning_rate": 8.122256460157856e-05,
      "loss": 0.8668,
      "step": 79500
    },
    {
      "epoch": 2.11,
      "learning_rate": 8.108768515515191e-05,
      "loss": 0.8696,
      "step": 80000
    },
    {
      "epoch": 2.12,
      "learning_rate": 8.095253540923344e-05,
      "loss": 0.8766,
      "step": 80500
    },
    {
      "epoch": 2.13,
      "learning_rate": 8.081738566331496e-05,
      "loss": 0.866,
      "step": 81000
    },
    {
      "epoch": 2.14,
      "learning_rate": 8.068223591739647e-05,
      "loss": 0.8689,
      "step": 81500
    },
    {
      "epoch": 2.16,
      "learning_rate": 8.054708617147801e-05,
      "loss": 0.8716,
      "step": 82000
    },
    {
      "epoch": 2.17,
      "learning_rate": 8.041193642555952e-05,
      "loss": 0.8691,
      "step": 82500
    },
    {
      "epoch": 2.18,
      "learning_rate": 8.027678667964104e-05,
      "loss": 0.8758,
      "step": 83000
    },
    {
      "epoch": 2.2,
      "learning_rate": 8.014163693372257e-05,
      "loss": 0.8689,
      "step": 83500
    },
    {
      "epoch": 2.21,
      "learning_rate": 8.000648718780409e-05,
      "loss": 0.867,
      "step": 84000
    },
    {
      "epoch": 2.22,
      "learning_rate": 7.987133744188561e-05,
      "loss": 0.8703,
      "step": 84500
    },
    {
      "epoch": 2.24,
      "learning_rate": 7.973618769596714e-05,
      "loss": 0.8757,
      "step": 85000
    },
    {
      "epoch": 2.25,
      "learning_rate": 7.960103795004866e-05,
      "loss": 0.8707,
      "step": 85500
    },
    {
      "epoch": 2.26,
      "learning_rate": 7.946588820413018e-05,
      "loss": 0.8701,
      "step": 86000
    },
    {
      "epoch": 2.28,
      "learning_rate": 7.933073845821171e-05,
      "loss": 0.871,
      "step": 86500
    },
    {
      "epoch": 2.29,
      "learning_rate": 7.919585901178506e-05,
      "loss": 0.8583,
      "step": 87000
    },
    {
      "epoch": 2.3,
      "learning_rate": 7.906070926586658e-05,
      "loss": 0.8733,
      "step": 87500
    },
    {
      "epoch": 2.32,
      "learning_rate": 7.892555951994811e-05,
      "loss": 0.8619,
      "step": 88000
    },
    {
      "epoch": 2.33,
      "learning_rate": 7.879040977402963e-05,
      "loss": 0.8667,
      "step": 88500
    },
    {
      "epoch": 2.34,
      "learning_rate": 7.865580062709483e-05,
      "loss": 0.8678,
      "step": 89000
    },
    {
      "epoch": 2.36,
      "learning_rate": 7.852092118066818e-05,
      "loss": 0.8706,
      "step": 89500
    },
    {
      "epoch": 2.37,
      "learning_rate": 7.838577143474971e-05,
      "loss": 0.8655,
      "step": 90000
    },
    {
      "epoch": 2.38,
      "learning_rate": 7.825062168883122e-05,
      "loss": 0.8696,
      "step": 90500
    },
    {
      "epoch": 2.39,
      "learning_rate": 7.811547194291275e-05,
      "loss": 0.8676,
      "step": 91000
    },
    {
      "epoch": 2.41,
      "learning_rate": 7.798032219699427e-05,
      "loss": 0.8696,
      "step": 91500
    },
    {
      "epoch": 2.42,
      "learning_rate": 7.78451724510758e-05,
      "loss": 0.8676,
      "step": 92000
    },
    {
      "epoch": 2.43,
      "learning_rate": 7.771002270515732e-05,
      "loss": 0.8661,
      "step": 92500
    },
    {
      "epoch": 2.45,
      "learning_rate": 7.757487295923884e-05,
      "loss": 0.865,
      "step": 93000
    },
    {
      "epoch": 2.46,
      "learning_rate": 7.743999351281221e-05,
      "loss": 0.8672,
      "step": 93500
    },
    {
      "epoch": 2.47,
      "learning_rate": 7.730484376689372e-05,
      "loss": 0.869,
      "step": 94000
    },
    {
      "epoch": 2.49,
      "learning_rate": 7.716996432046709e-05,
      "loss": 0.8665,
      "step": 94500
    },
    {
      "epoch": 2.5,
      "learning_rate": 7.703481457454861e-05,
      "loss": 0.8729,
      "step": 95000
    },
    {
      "epoch": 2.51,
      "learning_rate": 7.689966482863012e-05,
      "loss": 0.8665,
      "step": 95500
    },
    {
      "epoch": 2.53,
      "learning_rate": 7.676478538220348e-05,
      "loss": 0.8616,
      "step": 96000
    },
    {
      "epoch": 2.54,
      "learning_rate": 7.662963563628501e-05,
      "loss": 0.8643,
      "step": 96500
    },
    {
      "epoch": 2.55,
      "learning_rate": 7.649448589036653e-05,
      "loss": 0.8654,
      "step": 97000
    },
    {
      "epoch": 2.57,
      "learning_rate": 7.635933614444806e-05,
      "loss": 0.8672,
      "step": 97500
    },
    {
      "epoch": 2.58,
      "learning_rate": 7.622418639852957e-05,
      "loss": 0.8641,
      "step": 98000
    },
    {
      "epoch": 2.59,
      "learning_rate": 7.608930695210293e-05,
      "loss": 0.8695,
      "step": 98500
    },
    {
      "epoch": 2.61,
      "learning_rate": 7.595415720618446e-05,
      "loss": 0.8597,
      "step": 99000
    },
    {
      "epoch": 2.62,
      "learning_rate": 7.581900746026598e-05,
      "loss": 0.8669,
      "step": 99500
    },
    {
      "epoch": 2.63,
      "learning_rate": 7.56838577143475e-05,
      "loss": 0.8642,
      "step": 100000
    },
    {
      "epoch": 2.65,
      "learning_rate": 7.554870796842903e-05,
      "loss": 0.8581,
      "step": 100500
    },
    {
      "epoch": 2.66,
      "learning_rate": 7.541355822251055e-05,
      "loss": 0.8575,
      "step": 101000
    },
    {
      "epoch": 2.67,
      "learning_rate": 7.527840847659206e-05,
      "loss": 0.8616,
      "step": 101500
    },
    {
      "epoch": 2.68,
      "learning_rate": 7.51432587306736e-05,
      "loss": 0.859,
      "step": 102000
    },
    {
      "epoch": 2.7,
      "learning_rate": 7.500810898475511e-05,
      "loss": 0.8641,
      "step": 102500
    },
    {
      "epoch": 2.71,
      "learning_rate": 7.487295923883663e-05,
      "loss": 0.8682,
      "step": 103000
    },
    {
      "epoch": 2.72,
      "learning_rate": 7.473780949291816e-05,
      "loss": 0.861,
      "step": 103500
    },
    {
      "epoch": 2.74,
      "learning_rate": 7.460293004649151e-05,
      "loss": 0.8612,
      "step": 104000
    },
    {
      "epoch": 2.75,
      "learning_rate": 7.446778030057305e-05,
      "loss": 0.8566,
      "step": 104500
    },
    {
      "epoch": 2.76,
      "learning_rate": 7.433263055465456e-05,
      "loss": 0.8618,
      "step": 105000
    },
    {
      "epoch": 2.78,
      "learning_rate": 7.419748080873608e-05,
      "loss": 0.8608,
      "step": 105500
    },
    {
      "epoch": 2.79,
      "learning_rate": 7.40623310628176e-05,
      "loss": 0.8556,
      "step": 106000
    },
    {
      "epoch": 2.8,
      "learning_rate": 7.392718131689913e-05,
      "loss": 0.8662,
      "step": 106500
    },
    {
      "epoch": 2.82,
      "learning_rate": 7.379203157098064e-05,
      "loss": 0.8585,
      "step": 107000
    },
    {
      "epoch": 2.83,
      "learning_rate": 7.365688182506218e-05,
      "loss": 0.8638,
      "step": 107500
    },
    {
      "epoch": 2.84,
      "learning_rate": 7.352173207914369e-05,
      "loss": 0.8595,
      "step": 108000
    },
    {
      "epoch": 2.86,
      "learning_rate": 7.338658233322521e-05,
      "loss": 0.8626,
      "step": 108500
    },
    {
      "epoch": 2.87,
      "learning_rate": 7.325143258730674e-05,
      "loss": 0.8624,
      "step": 109000
    },
    {
      "epoch": 2.88,
      "learning_rate": 7.311628284138826e-05,
      "loss": 0.8558,
      "step": 109500
    },
    {
      "epoch": 2.9,
      "learning_rate": 7.298113309546978e-05,
      "loss": 0.8582,
      "step": 110000
    },
    {
      "epoch": 2.91,
      "learning_rate": 7.284598334955131e-05,
      "loss": 0.8607,
      "step": 110500
    },
    {
      "epoch": 2.92,
      "learning_rate": 7.271083360363283e-05,
      "loss": 0.8584,
      "step": 111000
    },
    {
      "epoch": 2.93,
      "learning_rate": 7.257568385771436e-05,
      "loss": 0.8574,
      "step": 111500
    },
    {
      "epoch": 2.95,
      "learning_rate": 7.244053411179588e-05,
      "loss": 0.8524,
      "step": 112000
    },
    {
      "epoch": 2.96,
      "learning_rate": 7.230538436587739e-05,
      "loss": 0.8501,
      "step": 112500
    },
    {
      "epoch": 2.97,
      "learning_rate": 7.217023461995893e-05,
      "loss": 0.8543,
      "step": 113000
    },
    {
      "epoch": 2.99,
      "learning_rate": 7.203508487404044e-05,
      "loss": 0.8568,
      "step": 113500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8379076719284058,
      "eval_runtime": 167.5192,
      "eval_samples_per_second": 596.947,
      "eval_steps_per_second": 18.655,
      "step": 113988
    }
  ],
  "max_steps": 379960,
  "num_train_epochs": 10,
  "total_flos": 1.5295643783204959e+18,
  "trial_name": null,
  "trial_params": null
}
