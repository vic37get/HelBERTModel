{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model_name = '/var/projetos/Jupyterhubstorage/victor.silva/brazilian-legal-text-bert/Modelos/epocas_HelBERT-base-uncased/checkpoint-epoca-30'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def score(model, tokenizer, sentence):\n",
    "    tensor_input = tokenizer.encode(sentence, return_tensors='pt', truncation=True, max_length=128)\n",
    "    repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
    "    mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
    "    masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "    labels = repeat_input.masked_fill( masked_input != tokenizer.mask_token_id, -100)\n",
    "    with torch.inference_mode():\n",
    "        loss = model(masked_input, labels=labels).loss\n",
    "    return np.exp(loss.item())\n",
    "\n",
    "print(score(sentence='Os furos das luminárias existentes deverão ser fechadas com argamassa e gesso. alkdjaklsjd asdlkjaslkdj adkljaklsdj asdlkjaskld asdklj klasdj asdjl adskjl.', model=model, tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "input_texts = [\"O objeto da licitação é a compra de comida.\"]\n",
    "results = perplexity.compute(model_id='/var/projetos/Jupyterhubstorage/victor.silva/brazilian-legal-text-bert/Modelos/epocas_HelBERT-base-uncased/checkpoint-epoca-30',\n",
    "                             add_start_token=False,\n",
    "                             predictions=input_texts)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/PreTreinamento/HelBERT-base-uncased/teste.txt') as f:\n",
    "    lines = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.DataFrame(lines, columns=['text'])\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Perplexidade/perplexidade_teste.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Perplexidade/LipSET.csv')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novas_sentencas = []\n",
    "for indice in dados.index:\n",
    "    frases = sent_tokenize(dados.loc[indice, 'text'])\n",
    "    novas_sentencas.extend(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.DataFrame(novas_sentencas, columns=['text'])\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['tamanho'] = dados['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['tamanho'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados[dados['tamanho'] >= 10]\n",
    "dados = dados[dados['tamanho'] <= 64]\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop_duplicates(inplace=True)\n",
    "dados.dropna(inplace=True)\n",
    "dados.reset_index(drop=True, inplace=True)\n",
    "dados.drop('tamanho', axis=1, inplace=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Perplexidade/LipSET-reduzida.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
