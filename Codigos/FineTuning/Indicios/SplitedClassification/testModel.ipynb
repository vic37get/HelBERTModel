{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from statistics import mean \n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataFrame: pd.DataFrame, labels: list, column: str, tokenizer: BertTokenizer,\n",
    "                  device: torch.device, modelo: BertModel) -> list:\n",
    "        self.X = dataFrame[column].tolist()\n",
    "        self.Y = dataFrame[labels].values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.modelo = modelo\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample=self.X[index]\n",
    "        sample=self.get_text_split(sample, self.tokenizer)\n",
    "        tokens = self.tokenize(sample, self.tokenizer)\n",
    "        tokens = { k: v.to(self.device) for k, v in tokens.items() }\n",
    "        with torch.no_grad():\n",
    "            output=self.modelo(input_ids=tokens['input_ids'],attention_mask=tokens['attention_mask'])\n",
    "        toks_embeds = torch.stack(output.hidden_states)\n",
    "        try:\n",
    "            toks_embeds = toks_embeds[12]\n",
    "        except:\n",
    "            toks_embeds = toks_embeds[6]\n",
    "        embed_final=torch.mean(torch.mean(toks_embeds, dim=1), dim=0)\n",
    "        return embed_final, self.Y[index]\n",
    "    \n",
    "    def get_text_split(self, text: str, tokenizer: BertTokenizer, length: int = 200, overlap: int = 0, max_chunks: int = 200) -> list:\n",
    "        \"\"\"\n",
    "        Função que divide o texto em pedaços de tamanho length com overlap de tamanho overlap.\n",
    "        Parâmetros:\n",
    "            text: texto a ser dividido\n",
    "            length: tamanho de cada pedaço\n",
    "            overlap: tamanho da sobreposição entre os pedaços\n",
    "            max_chunks: número máximo de pedaços\n",
    "        Retorno:\n",
    "            l_total: lista com os pedaços do texto\n",
    "        \"\"\"\n",
    "        l_total = []\n",
    "        l_parcial = []\n",
    "        n_words = len(text.split()) \n",
    "        #n_words = len(tokenizer.tokenize(text))\n",
    "        n = n_words//(length-overlap)+1\n",
    "        if n_words % (length-overlap) == 0:\n",
    "            n = n-1\n",
    "        if n ==0:\n",
    "            n = 1\n",
    "        n = min(n, max_chunks)\n",
    "        for w in range(n):\n",
    "            if w == 0:\n",
    "                l_parcial = text.split()[:length]\n",
    "            else:\n",
    "                l_parcial = text.split()[w*(length-overlap):w*(length-overlap) + length]\n",
    "            l = \" \".join(l_parcial)\n",
    "            if w==n-1:\n",
    "                if len(l_parcial) < 0.75*length and n!=1:\n",
    "                    continue\n",
    "            l_total.append(l)\n",
    "        return l_total\n",
    "    \n",
    "    def tokenize(self, text: str, tokenizer: BertTokenizer) -> dict:\n",
    "        \"\"\"\n",
    "        Função que tokeniza o texto.\n",
    "        Parâmetros:\n",
    "            text: texto a ser tokenizado\n",
    "            tokenizer: tokenizer\n",
    "        Retorno:\n",
    "            tokens: dicionário com os tokens\n",
    "        \"\"\"\n",
    "        text = list(text)\n",
    "        tokens = tokenizer(\n",
    "            text, \n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {'input_ids': tokens['input_ids'], 'attention_mask': tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.trans = torch.nn.TransformerEncoderLayer(d_model=768, nhead=2)\n",
    "        self.fc = torch.nn.Linear(768, 30)\n",
    "        self.classifier = torch.nn.Linear(30, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.trans(x.unsqueeze(0))\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_func(batch: list) -> list:\n",
    "    \"\"\"\n",
    "    Função que prepara o batch para ser passado para o modelo.\n",
    "    Parâmetros:\n",
    "        batch: batch de dados\n",
    "    Retorno:\n",
    "        X: lista com os textos\n",
    "        Y: lista com os labels\n",
    "    \"\"\"\n",
    "    X = [x[0] for x in batch]\n",
    "    Y = [x[1] for x in batch]\n",
    "    return [X,Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERT/Datasets/Indicios/bid_notices_weak/dataset_bid_notices_weak_treino.csv')\n",
    "teste = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERT/Datasets/Indicios/bid_notices_weak/dataset_bid_notices_weak_teste.csv')\n",
    "validacao = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERT/Datasets/Indicios/bid_notices_weak/dataset_bid_notices_weak_validacao.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.concat([treino, teste, validacao])\n",
    "dados.reset_index(drop=True, inplace=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[dados['n_min_max_limitacao_atestados'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "model_embedding = AutoModel.from_pretrained(model_name, output_hidden_states=True).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dados.columns.values.tolist()[1:]\n",
    "data = MyDataset(dados, labels, 'text', tokenizer, device, model_embedding)\n",
    "test_loader = DataLoader(dataset=data, batch_size=4, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(input_size = 768, output_size=7).to(device)\n",
    "classifier.load_state_dict(torch.load('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Modelos/Indicios/SplitedClassification/BERTimbau-model.pth')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(test_loader: DataLoader):\n",
    "    \"\"\"\n",
    "    Função que realiza o teste do modelo.\n",
    "    Parâmetros:\n",
    "        test_loader: dataloader de validação\n",
    "        device: dispositivo a ser utilizado\n",
    "        epoch: época atual\n",
    "    Retorno:\n",
    "        metricas: dicionário com as métricas de teste.\n",
    "    \"\"\"\n",
    "    classifier.eval()        \n",
    "    preds=[]\n",
    "    trues=[]\n",
    "    test_losses=[]\n",
    "    loop = tqdm(test_loader, leave=True, colour='yellow')\n",
    "    for embeddings, labels in loop:\n",
    "        embeddings=torch.stack(embeddings).to(device)\n",
    "        logits=classifier(embeddings)\n",
    "        loss=None\n",
    "        labels=torch.tensor(labels,dtype=float).to(device)\n",
    "        loss=criterion(logits.squeeze(0),labels)\n",
    "        loop.set_description(f'Realizando o teste')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        test_losses.append(float(loss.detach().cpu().numpy()))\n",
    "        probs=torch.sigmoid(logits)\n",
    "        predictions=torch.clone(probs)\n",
    "        predictions[predictions >= 0.5] = 1\n",
    "        predictions[predictions < 0.5] = 0\n",
    "        preds.append(torch.tensor(predictions.cpu().detach().numpy()).squeeze(0))\n",
    "        trues.append(torch.tensor(labels.cpu().detach().numpy())) \n",
    "    y_true=torch.cat(trues,0)\n",
    "    y_pred=torch.cat(preds,0)\n",
    "    precisao=precision_score(y_true, y_pred,average='weighted',zero_division=0)\n",
    "    recall=recall_score(y_true, y_pred,average='weighted', zero_division=0)\n",
    "    f1=f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
    "    acuracia=accuracy_score(y_true, y_pred)\n",
    "    cf_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return {'test_losses': mean(test_losses), 'precision':precisao, 'recall':recall, 'f1':f1, 'accuracy':acuracia, 'cf_report':cf_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertimbau = test_step(test_loader)\n",
    "bertimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(bertimbau, open('metricasWeakBertimbau.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
