{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executando data augmentation das colunas idoneidade_financeira, n_min_max_limitacao_atestados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gold = pd.read_csv(\"/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/dataset_bid_notices_weak_sup_hab_clean_selected.csv\")\n",
    "data_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gold = data_gold.drop_duplicates()\n",
    "data_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificaLabels(data):\n",
    "    for coluna in data.columns[1:]:\n",
    "        print(data[coluna].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(data_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = data_gold.columns[1:]\n",
    "colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_without_da(data, colunas, coluna_exception):\n",
    "    dados_filtrados = []\n",
    "    for indice in data.index:\n",
    "        if (data.loc[indice, colunas[0]] == 1 or data.loc[indice, colunas[1]] == 1) and (data.loc[indice, coluna_exception] == 0):\n",
    "            dados_filtrados.append(data.iloc[indice])\n",
    "    return pd.DataFrame(dados_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(data_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentated = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/DataAugmentation/data_back_translated_n_min_max_idoneidade_financeira.csv')\n",
    "data_augmentated.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_augmentated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(data_augmentated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gold = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/dataset_bid_notices_weak_sup_hab_clean_selected.csv')\n",
    "data_gold.drop_duplicates(inplace=True)\n",
    "data_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_da(data, colunas, coluna_exception):\n",
    "    dados_filtrados = []\n",
    "    for indice in data.index:\n",
    "        if (data.loc[indice, colunas[0]] == 1 or data.loc[indice, colunas[1]] == 1) and (data.loc[indice, coluna_exception] == 0):\n",
    "            dados_filtrados.append(data.iloc[indice])\n",
    "    return pd.DataFrame(dados_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = get_df_without_da(data_gold, ['n_min_max_limitacao_atestados', 'idoneidade_financeira'], 'comprovante_localizacao')\n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(data_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_data_augmentation(real_data, data_augmentated, columns_data_augmented, column_exception, train_ratio = 0.8, test_ratio = 0.1, val_ratio = 0.1):\n",
    "    # Remove as linhas em que a classe com data_augmentation é 1.\n",
    "    data_without_data_augmented = real_data.drop(get_df_with_da(real_data, columns_data_augmented, column_exception).index)\n",
    "    #data_without_data_augmented = real_data[real_data[column_data_augmented] != 1]\n",
    "    mskf_train_test = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mskf_test_val = MultilabelStratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    # Pega as colunas que serão as classes, sem a coluna de texto.\n",
    "    target=data_without_data_augmented.drop(['text'], axis=1).values\n",
    "    # Divide em teste e treino 80/20 estratificado.\n",
    "    train_index, test_index = list(mskf_train_test.split(X=data_without_data_augmented.values, y=target))[0]\n",
    "    # Divisão em teste e validação 50/50 estratificado.\n",
    "    target = data_without_data_augmented.iloc[test_index].drop(['text'], axis=1).values\n",
    "    test_index, val_index = list(mskf_test_val.split(X=data_without_data_augmented.iloc[test_index].values, y=target))[0]\n",
    "    \n",
    "    # Datasets pré-criados.\n",
    "    train_df = data_without_data_augmented.iloc[train_index]\n",
    "    test_df = data_without_data_augmented.iloc[test_index]\n",
    "    val_df = data_without_data_augmented.iloc[val_index]\n",
    "    \n",
    "    # Tratando o conjunto de dados com data_augmentation.\n",
    "    data_real_column_data_augmented = get_df_with_da(real_data, columns_data_augmented, column_exception)\n",
    "    #data_real_column_data_augmented = real_data[real_data[column_data_augmented] == 1]\n",
    "    # Quantidade de amostras data augmentation e reais.\n",
    "    len_samples = len(data_real_column_data_augmented) + len(data_augmentated)\n",
    "    len_train, len_test, len_valid = round(len_samples * train_ratio), round(len_samples * test_ratio), round(len_samples * val_ratio)\n",
    "    \n",
    "    # Inserção de amostras de teste reais.\n",
    "    if len_test <= len(data_real_column_data_augmented):\n",
    "        samples_test = data_real_column_data_augmented.sample(len_test)\n",
    "        data_real_column_data_augmented.drop(samples_test.index, inplace=True)\n",
    "        test_df = pd.concat([test_df, samples_test]).reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError('A quantidade de amostras de reais é insuficiente para a divisão de teste.')\n",
    "    \n",
    "    # Inserção de amostras de validação reais.\n",
    "    if len_valid <= len(data_real_column_data_augmented):\n",
    "        samples_valid = data_real_column_data_augmented.sample(len_valid)\n",
    "        data_real_column_data_augmented.drop(samples_valid.index, inplace=True)\n",
    "        val_df = pd.concat([val_df, samples_valid]).reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError('A quantidade de amostras de reais é insuficiente para a divisão de validação.')\n",
    "    \n",
    "    # Inserção das amostras reais restantes e as de data_augmentation no conjunto de treino\n",
    "    train_df = pd.concat([train_df, data_augmentated, data_real_column_data_augmented]).reset_index(drop=True)\n",
    "    return train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, val_df = stratified_data_augmentation(data_gold, data_augmentated, ['n_min_max_limitacao_atestados', 'idoneidade_financeira'], 'comprovante_localizacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verificaLabels(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/DataAugmentation/bid_notices_weak_sup_hab_clean_train.csv', index=False)\n",
    "test_df.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/DataAugmentation/bid_notices_weak_sup_hab_clean_test.csv', index=False)\n",
    "val_df.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/DataAugmentation/bid_notices_weak_sup_hab_clean_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mskf_train_test = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "mskf_test_val = MultilabelStratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "target = data_gold.drop(['text'], axis=1).values\n",
    "train_index, test_index = list(mskf_train_test.split(X=data_gold.values, y=target))[0]\n",
    "target = data_gold.iloc[test_index].drop(['text'], axis=1).values\n",
    "test_index, val_index = list(mskf_test_val.split(X=data_gold.iloc[test_index].values, y=target))[0]\n",
    "\n",
    "df_train = data_gold.iloc[train_index].reset_index(drop=True)\n",
    "df_test = data_gold.iloc[test_index].reset_index(drop=True)\n",
    "df_val = data_gold.iloc[val_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/Stratified/bid_notices_weak_sup_hab_clean_train.csv', index=False)\n",
    "df_test.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/Stratified/bid_notices_weak_sup_hab_clean_test.csv', index=False)\n",
    "df_val.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/DatasetsWeak/Stratified/bid_notices_weak_sup_hab_clean_val.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
