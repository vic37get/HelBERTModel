{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from cleaner import Cleaner, Corretor\n",
    "from tqdm.auto import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Objetos/df_tipos_objetos.csv')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['tamanho'] = dados['text'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "dados['tamanho'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.reset_index(drop=True, inplace=True)\n",
    "dados.drop(columns=['tamanho'], inplace=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino, teste = train_test_split(dados, test_size=0.3, random_state=42, stratify=dados['label'], shuffle=True)\n",
    "teste, validacao = train_test_split(teste, test_size=0.5, random_state=42, stratify=teste['label'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.reset_index(drop=True, inplace=True)\n",
    "teste.reset_index(drop=True, inplace=True)\n",
    "validacao.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Objetos/df_tipos_objetos_treino.csv', index=False)\n",
    "teste.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Objetos/df_tipos_objetos_teste.csv', index=False)\n",
    "validacao.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Objetos/df_tipos_objetos_validacao.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/gold_completo_raw.csv')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['certidao_protesto', 'certificado_boas_praticas', 'comprovante_localizacao', 'idoneidade_financeira', 'integralizado', 'licenca_ambiental', 'n_min_max_limitacao_atestados']\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in columns:\n",
    "    dados[coluna] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indice in dados.index:\n",
    "    for label in eval(dados['annotation'][indice]):\n",
    "        if label in columns:\n",
    "            dados.at[indice, label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(columns=['annotation'], inplace=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executaLimpeza(dataframe: pd.DataFrame, column: str, cased: bool, accents: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executa a limpeza do DataFrame usando as classes Cleaner e Corretor.\n",
    "    \"\"\"\n",
    "    sentencesDrop = []\n",
    "    for indice in tqdm(dataframe.index, desc=\"Executando a Limpeza\", colour='yellow'):\n",
    "        texto = dataframe[column][indice]\n",
    "        if isinstance(texto, str):\n",
    "            texto = Cleaner().clear(texto)\n",
    "            texto = Corretor(cased, accents).corrige_termos(texto)\n",
    "            dataframe.at[indice, column] = texto\n",
    "        else:\n",
    "            sentencesDrop.append(indice)\n",
    "    dataframe = dataframe.drop(sentencesDrop)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = executaLimpeza(dados, 'text', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dropna(subset=['text'], inplace=True)\n",
    "dados.drop_duplicates(subset=['text'], inplace=True)\n",
    "dados.reset_index(drop=True, inplace=True)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(dados.values, dados[dados.columns[1:]].values, test_size = 0.25)\n",
    "X_test, y_test, X_val, y_val = iterative_train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pd.DataFrame(X_train, columns=dados.columns)\n",
    "teste = pd.DataFrame(X_test, columns=dados.columns)\n",
    "validacao = pd.DataFrame(X_val, columns=dados.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/dataset_bid_notices_gold_treino.csv', index=False)\n",
    "teste.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/dataset_bid_notices_gold_teste.csv', index=False)\n",
    "validacao.to_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/Indicios/dataset_bid_notices_gold_validacao.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ner Indicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino = pickle.load(open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERT/Datasets/Indicios/bid_notices_weak/dataset_bid_notices_weak_hab_clean_treino_chunk_more.pkl', 'rb'))\n",
    "teste = pickle.load(open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERT/Datasets/Indicios/bid_notices_weak/dataset_bid_notices_weak_hab_clean_teste_chunk_more.pkl', 'rb'))\n",
    "validacao = pickle.load(open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERT/Datasets/Indicios/bid_notices_weak/dataset_bid_notices_weak_hab_clean_validacao_chunk_more.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Perplexidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/PreTreinamento/dfPreTreinamento-base-uncased.csv')\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = dados['text'].tolist()[:100000]\n",
    "treinamento = dados['text'].tolist()[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/PreTreinamento/teste.txt', 'w') as file:\n",
    "    for texto in teste:\n",
    "        file.write(texto + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/PreTreinamento/HelBERT-base-uncased/treino.txt', 'w') as file:\n",
    "    for texto in treinamento:\n",
    "        file.write(texto + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLM Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavrasIRb = json.load(open('/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Datasets/MaskedLanguageModeling/tesauroIRB3Palavras.json'))\n",
    "palavrasIRb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_palavras = []\n",
    "for palavra in palavrasIRb:\n",
    "    lista_palavras.append(palavra['Palavra'])\n",
    "    lista_palavras.append(palavra['Relacionada'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_palavras = list(set(lista_palavras))\n",
    "lista_palavras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
