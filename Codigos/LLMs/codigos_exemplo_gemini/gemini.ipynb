{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import chromadb\n",
    "import re\n",
    "import time\n",
    "from pypdf import PdfReader\n",
    "import google.generativeai as genai\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from tqdm.auto import tqdm\n",
    "os.environ[\"GEMINI_API_KEY\"]=\"AIzaSyBOuvb9pa0OuOd4Npiu-jZMR4OYDDA1TvM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"Me forneça um exemplo de edital de licitação\")\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(\"Me faça um relatório de auditoria sobre a empresa XPTO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_tokens(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Reads the text content from a PDF file and returns it as a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The concatenated text content of all pages in the PDF.\n",
    "    \"\"\"\n",
    "    # Logic to read pdf\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    # Loop over each page and store it in a variable\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str):\n",
    "    \"\"\"\n",
    "    Splits a text string into a list of non-empty substrings based on the specified pattern.\n",
    "    The \"\\n \\n\" pattern will split the document para by para\n",
    "    Parameters:\n",
    "    - text (str): The input text to be split.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing non-empty substrings obtained by splitting the input text.\n",
    "\n",
    "    \"\"\"\n",
    "    split_text = re.split('\\n', text)\n",
    "    return [i for i in split_text if i != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"\n",
    "    Custom embedding function using the Gemini AI API for document retrieval.\n",
    "\n",
    "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
    "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
    "\n",
    "    Parameters:\n",
    "    - input (Documents): A collection of documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - Embeddings: Embeddings generated for the input documents.\n",
    "    \"\"\"\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = \"models/text-embedding-004\"\n",
    "        title = \"Custom query\"\n",
    "        return genai.embed_content(model=model,\n",
    "                                   content=input,\n",
    "                                   task_type=\"retrieval_document\",\n",
    "                                   title=title)[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_db(documents: list, path:str, name:str):\n",
    "    \"\"\"\n",
    "    Creates a Chroma database using the provided documents, path, and collection name.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: An iterable of documents to be added to the Chroma database.\n",
    "    - path (str): The path where the Chroma database will be stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "        db.add(documents=d, ids=str(i))\n",
    "            \n",
    "    return db, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_collection(path, name):\n",
    "    \"\"\"\n",
    "    Loads an existing Chroma collection from the specified path with the given name.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The path where the Chroma database is stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - chromadb.Collection: The loaded Chroma Collection.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db, n_results):\n",
    "  passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "  return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text  = load_pdf(\"/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Codigos/LLMs/Documentos/EDITAL CORRETO.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text = split_text(text=pdf_text)\n",
    "if os.path.exists(\"./db\"):\n",
    "    shutil.rmtree(\"./db\")\n",
    "    os.makedirs(\"./db\")\n",
    "else:\n",
    "    os.makedirs(\"./db\")\n",
    "db,name =create_chroma_db(documents=chunked_text, \n",
    "                          path=\"./db\",\n",
    "                          name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_prompt(query, relevant_passage):\n",
    "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = (\"\"\"Você é um bot prestativo e informativo que responde a perguntas usando o texto do trecho de referência incluído abaixo. \\\n",
    "  Certifique-se de responder de forma completa, sendo abrangente, incluindo todas as informações relevantes de contexto. \\\n",
    "  No entanto, você está falando com um público não técnico, por isso, é importante simplificar conceitos complicados e \\\n",
    "  manter um tom amigável e conversacional. \\\n",
    "  Se o trecho não for relevante para a resposta, você pode ignorá-lo.\n",
    "  PERGUNTA: '{query}'\n",
    "  TRECHO: '{relevant_passage}'\n",
    "\n",
    "  RESPOSTA:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, db):\n",
    "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
    "    prompt = make_rag_prompt(query, \n",
    "                             relevant_passage=\"\".join(relevant_text))\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
    "    answer = model.generate_content(prompt)\n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=load_chroma_collection(path=\"./db\", name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = generate_answer(db=db, query=\"Qual é o objeto da licitação?\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
