{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgALz5M7I9dQ"
      },
      "outputs": [],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELCq2M4XJ467"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NOFOt74X2Gd"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG_3KsGRKDYU",
        "outputId": "a41da251-cf48-49c4-8586-90246c55a468"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name = \"models/gemini-1.5-flash\")\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-2GbIa-KaUb"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\"Quais são os sintomas da COVID-19?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "i9TTvRUfKmBg",
        "outputId": "2c917d55-e6a5-461c-905f-373e9d9319c1"
      },
      "outputs": [],
      "source": [
        "to_markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TbsjM7hK6PR"
      },
      "source": [
        "### Use LangChain to Access Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqdODsdLK8li"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vknP_oOWK-k7"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash\",google_api_key=os.environ[\"GEMINI_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvY2YkFoLDO7"
      },
      "outputs": [],
      "source": [
        "result = llm.invoke(\"Descreva o que é distributiva, estabilizadora e alocativa?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ar8KNtZILE47",
        "outputId": "f96581b4-6693-48c9-f33d-7a4867f9d34d"
      },
      "outputs": [],
      "source": [
        "to_markdown(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7EjS_0qMLwyb"
      },
      "outputs": [],
      "source": [
        "__import__('pysqlite3')\n",
        "import sys\n",
        "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
        "import urllib\n",
        "import warnings\n",
        "from pathlib import Path as p\n",
        "import os\n",
        "from pprint import pprint\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import pandas as pd\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "os.environ[\"GEMINI_API_KEY\"]=\"AIzaSyBOuvb9pa0OuOd4Npiu-jZMR4OYDDA1TvM\"\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HXXP0LCKN9pD"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash\",google_api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "                             temperature=0.2,convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fVI3d0BPaPQ"
      },
      "source": [
        "### Extract text from the PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kz7Ek2KPKSy",
        "outputId": "918ac57f-f7c2-4abf-e6c0-dc14e76f56ba"
      },
      "outputs": [],
      "source": [
        "pdf_loader = PyPDFLoader(\"/var/projetos/Jupyterhubstorage/victor.silva/HelBERTModel/Codigos/LLMs/Documentos/PREGÃO ELETRÔNICO mat INFORMATICA.pdf\")\n",
        "pages = pdf_loader.load_and_split()\n",
        "print(pages[3].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ7OlzvWSRE1"
      },
      "source": [
        "### RAG Pipeline: Embedding + Gemini (LLM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xCLmdnHYdoVx"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5VCQ2XiUSTOl"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
        "context = \"\\n\\n\".join(str(p.page_content) for p in pages)\n",
        "texts = text_splitter.split_text(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oenB_PKkSpr_"
      },
      "outputs": [],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=os.environ[\"GEMINI_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zRDgzSjsSZtG"
      },
      "outputs": [],
      "source": [
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "a3CrM0l3Hc__"
      },
      "outputs": [],
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "C683CMhDHtA8",
        "outputId": "428765b5-fcb0-4d0a-e02d-85f1ae945ad1"
      },
      "outputs": [],
      "source": [
        "question = \"Quais são os requisitos para participar do pregão eletrônico? Traga exatamente como está no edital.\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "gR9NB2OLIp7I",
        "outputId": "2dce7ad5-48e5-46a8-869b-c6600a57e877"
      },
      "outputs": [],
      "source": [
        "Markdown(result[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JExbG1VNcDZ",
        "outputId": "2332827f-e07c-4d1e-d04f-17610a586d90"
      },
      "outputs": [],
      "source": [
        "result[\"source_documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGFjxwzcUb02"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    model,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "og-CJ7iaMYJe",
        "outputId": "40ca7734-c20e-4584-8670-397f733a46b6"
      },
      "outputs": [],
      "source": [
        "question = \"Describe the Multi-head attention layer in detail?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "BwZpAwFWMbor",
        "outputId": "9a43e671-9d98-40cb-c32a-3b66a951cfda"
      },
      "outputs": [],
      "source": [
        "Markdown(result[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "CFNBXo0kJKkA",
        "outputId": "28022889-a62a-4a8e-ef23-65ea72fddf69"
      },
      "outputs": [],
      "source": [
        "question = \"Describe Random forest?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "Markdown(result[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
